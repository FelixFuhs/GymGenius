Below is a **drop-in `TECHNICAL_SPEC.md`** tailored to **GymGenius** and written in the same voice / structure as your â€œSchwerhÃ¶rige-Hexe Benchmarkâ€ spec.

```markdown
# **TECHNICAL SPECIFICATION â€“ â€œGymGenius Adaptive Coachâ€**

*Version 1.0 â€“ 14 Jun 2025*

---

## 1 Â· Project Overview

GymGenius is a **monorepo** that ships a mobile-first PWA, a Node API, and a Python ML micro-service.  
Goal: deliver real-time weight/rep/rest prescriptions that adapt to each userâ€™s history, recovery, and goals.

**Pipeline (stateless per service):**

1. **Web PWA** â€“ logs set, fetches recommendation via REST.
2. **API** â€“ auth, validation, orchestration, queues jobs.
3. **Engine** â€“ gRPC micro-service; predicts weight, learns RIR-bias & recovery Ï„.
4. **Worker** â€“ nightly fine-tunes models, aggregates analytics.
5. **Storage** â€“ Postgres (relational), Redis (cache/queue), S3 (model ckpts, exports).
6. **Observability** â€“ OpenTelemetry traces, Sentry errors, Datadog metrics.

All compute nodes are **stateless**; persistence lives only in Postgres, Redis, and S3.

---

## 2 Â· Repository / File Structure

```

gymgenius/
â”œâ”€â”€ README.md              # pitch + quick-start
â”œâ”€â”€ ROADMAP.md             # phase backlog
â”œâ”€â”€ ARCHITECTURE.md        # service registry + diagrams
â”œâ”€â”€ AGENT\_GUIDE.md         # bot rules
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/               # React + TS PWA
â”‚   â””â”€â”€ api/               # Express/Fastify service
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ engine/            # PyTorch adaptive engine
â”‚   â””â”€â”€ worker/            # Bull queue consumer
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ ui/                # Tailwind component library
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.prisma
â”‚   â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ seed.ts
â”œâ”€â”€ infra/                 # Terraform / ECS / GitHub Actions manifests
â”œâ”€â”€ scripts/               # one-off helpers
â””â”€â”€ tests/
â”œâ”€â”€ web/
â”œâ”€â”€ api/
â””â”€â”€ engine/

````

### 2.1 Key Files

| File / Dir                 | Purpose                                                         | Notable Imports / Tools                |
|----------------------------|-----------------------------------------------------------------|----------------------------------------|
| **schema.prisma**          | Postgres schema incl. enums, relations                          | Prisma ORM                             |
| **engine/model.py**        | PyTorch-Lightning module (extended Epley, Bayesian layers)      | torch, pyro-ppl                        |
| **engine/api.proto**       | gRPC contract (`PredictSet`, `WarmStart`)                       | protobuf 3                             |
| **api/routes/sets.ts**     | `POST /sets` & `GET /recommendation`                            | zod validation, OpenAPI decorators     |
| **worker/train.py**        | Nightly fine-tune script, pushes ckpt to S3                     | boto3, pandas                          |
| **web/src/hooks/usePredict.ts** | React SWR hook â†’ `/recommendation`                          | zustand, ky, msw                       |
| **infra/ci.yml**           | GitHub Actions: lint-test-docker-deploy                         | pnpm, pytest, ruff, kubectl            |

---

## 3 Â· Data-Flow Specification

### 3.1 Core Prisma Models

```prisma
model User {
  id              String   @id @default(uuid())
  email           String   @unique
  passwordHash    String
  goalSlider      Float    @default(0.5)   // 0 = hypertrophy, 1 = strength
  rirBias         Float    @default(2.0)
  createdAt       DateTime @default(now())
  workouts        Workout[]
}

model Workout {
  id          String   @id @default(uuid())
  user        User     @relation(fields: [userId], references: [id])
  userId      String
  startedAt   DateTime
  completedAt DateTime?
  sessionRpe  Int?
  sets        WorkoutSet[]
}

model WorkoutSet {
  id                 String  @id @default(uuid())
  workout            Workout @relation(fields: [workoutId], references: [id])
  workoutId          String
  exerciseId         String
  setNumber          Int
  recommendedWeight  Float
  recommendedRepsLo  Int
  recommendedRepsHi  Int
  recommendedRir     Int
  confidence         Float
  actualWeight       Float?
  actualReps         Int?
  actualRir          Int?
  completedAt        DateTime?
  @@index([exerciseId, completedAt])
}
````

### 3.2 `POST /recommendation` (API â†’ Engine)

| Field           | Type      | Description                        |
| --------------- | --------- | ---------------------------------- |
| `user_id`       | UUID      |                                    |
| `exercise_id`   | UUID      |                                    |
| `set_number`    | int       | 1-based index within session       |
| `goal_strength` | float     | 0-1 slider                         |
| `history`       | object\[] | last 12 sets `{w,r,rir,timestamp}` |

`api` maps the JSON body to `PredictSetRequest` (proto) and forwards synchronously to `engine`.

### 3.3 `engine` Response

```jsonc
{
  "weight": 80.0,          // kg, pre-rounded
  "rep_low": 6,
  "rep_high": 8,
  "rir": 2,
  "confidence": 0.83,
  "explanation": "load derived from 1RM 105.2kg, fatigue âˆ’5%"
}
```

`api` persists the recommendation, applies plate rounding, returns to web.

---

## 4 Â· Algorithmic Core (Engine)

* **Load estimation** â€“ Extended Epley with user-specific RIR-bias:
  $\hat{1RM} = \frac{w}{1 - 0.0333\,(r + \max(0,\,RIR - b_u))}$

* **Goal interpolation** (see `calculate_training_params` in spec).

* **Fatigue decay** â€“ impulse-response:
  $F_t = \sum V\!L_j^\alpha e^{-\beta\Delta t}$; personalised $\alpha,\beta$ via HMC.

* **Readiness modifier** â€“ z-score of HRV, sleep, fatigue questionnaire â†’ Â±7 %.

* **Guardrails** â€“ clamp inter-session load delta â‰¤ 7.5 %.

`model.py` exports two public methods:

```python
def predict(request: PredictSetRequest) -> PredictSetResponse: ...
def warm_start(user_id: str) -> None  # batch import of history
```

---

## 5 Â· REST API Surface (OpenAPI snippets)

| Verb   | Path                   | Purpose                             | Auth   |
| ------ | ---------------------- | ----------------------------------- | ------ |
| `POST` | `/v1/login`            | JWT issuance                        | none   |
| `POST` | `/v1/sets`             | Log actual performance              | Bearer |
| `POST` | `/v1/recommendation`   | Get next-set prescription           | Bearer |
| `GET`  | `/v1/analytics/volume` | Muscle-volume weekly graph          | Bearer |
| `POST` | `/v1/plan/compile`     | Generate workout template from goal | Bearer |

All endpoints validated with **zod** â†’ automatic OpenAPI JSON.

---

## 6 Â· Dev Environment & Commands

```bash
# spin up full stack
make dev

# run linters
make lint      # eslint + ruff

# run tests
make test      # jest + pytest

# DB migration (dev)
pnpm db:migrate:dev

# gRPC stubs regen
make proto
```

---

## 7 Â· Logging & Monitoring

| Layer  | Library           | Format â†’ Sink                                 | Notes             |
| ------ | ----------------- | --------------------------------------------- | ----------------- |
| Node   | pino              | JSON â†’ stdout                                 | trace-ID attached |
| Python | structlog         | JSON â†’ stdout                                 |                   |
| Traces | opentelemetry SDK | OTLP â†’ Datadog APM                            | 90-day retention  |
| Alerts | Datadog           | **P95** `/predict` > 300 ms, error rate > 2 % |                   |

---

## 8 Â· Implementation Phases & Milestones (superset of ROADMAP)

| Phase | Modules                           | Goal                       | Tests                    |
| ----- | --------------------------------- | -------------------------- | ------------------------ |
| **0** | `database`, auth scaffold         | Schema locked, login works | prisma client unit tests |
| **1** | `engine` v0 (pure Extended Epley) | Prediction â‰¤ Â±10 % MAE     | pytest fixture history   |
| **2** | `web` logging loop                | 3-tap set logging UX       | cypress e2e smoke        |
| **3** | fatigue & readiness layer         | MAE â‰¤ 5 %; guardrails pass | scenario tests           |
| **4** | plan templates & analytics        | day-7 retention â‰¥ 50 users | jest snapshots           |
| **5** | staging env, observability        | <150 ms P95 latency        | k6 load test             |
| **6** | subscription Stripe flow          | revenue > \$0              | stripe mock tests        |

*MVP = Phases 0â€“3.*

---

## 9 Â· Edge Cases & Guardrails

| Case                               | Handling                                         |
| ---------------------------------- | ------------------------------------------------ |
| **Weight jump request > 7.5 %**    | Engine clamps, returns `flag: "hard_cap"`        |
| **User logs `RIR = â€“1`**           | Reject 422, front-end tooltip                    |
| **Set not logged within 30 min**   | Session auto-expires; next workout bump rest day |
| **Engine latency > 1 s**           | API falls back to last-session heuristic         |
| **Cold start (no history at all)** | Onboard 5-rep AMRAP test; population priors      |
| **JWT expired**                    | 401 â†’ web triggers silent refresh & retry        |

---

## 10 Â· Best-Practices Checklist

* **Typing** â€“ `tsconfig strict` Â· `mypy --strict`.
* **Secrets** â€“ .env only; populated via AWS Secrets Manager in prod.
* **CI** â€“ lint â†’ test â†’ docker build â†’ trivy scan; fail fast.
* **Async** â€“ Node routes non-blocking; Python uses `asyncio`, no GIL-heavy ops.
* **Docs** â€“ every public fn/docstring + OpenAPI auto-generated.
* **Coverage** â‰¥ 80 % lines for **both** stacks.
* **Containers** â€“ rootless; health-check `/healthz`.
* **Guardrails** â€“ weight delta â‰¤ 7.5 %, volume delta â‰¤ 30 %.
* **Observability** â€“ trace ID propagated (`x-request-id`) across services.

---

## 11 Â· Dependencies (â‰¥ Version)

| Package                    | Purpose                  |
| -------------------------- | ------------------------ |
| **node** 18 LTS            | API & web runtime        |
| **pnpm** 9.x               | Monorepo package manager |
| **react** 19.x             | Front-end                |
| **zustand** 4.x            | State management         |
| **tailwindcss** 4.x        | Styles                   |
| **express / fastify** 4    | API server               |
| **prisma** 5.x             | ORM                      |
| **grpc-tools** 1.63        | Proto codegen            |
| **python** 3.11            | ML engine                |
| **pytorch-lightning** 2    | Training loop            |
| **pyro-ppl** 1.x           | Bayesian layers          |
| **structlog** 24           | JSON logs                |
| **ruff** 0.4               | Python linter            |
| **jest** 30 / **pytest** 8 | Tests (TS / Py)          |
| **open-telemetry** 1.26    | Tracing                  |
| **sentry-sdk** 2.0         | Error tracking           |
| **aws-cli / boto3**        | S3 model store           |

---

## 12 Â· Next Steps

1. **Clone repo**, create `.env`, run `make dev`.
2. Implement **Phase 0** migrations â†’ `pnpm db:generate`.
3. Smokeâ€test `POST /recommendation` with sample history (script in `scripts/demo.py`).
4. Keep `ROADMAP.md` in syncâ€”bots rely on task IDs.

*Specification complete â€“ further questions should be answerable by this document or existing meta-files.* ğŸ’ª

```


